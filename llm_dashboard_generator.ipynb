{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TITLE ARTICLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install elasticsearch openai pydantic langchain-openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "import uuid\n",
    "from getpass import getpass\n",
    "from typing import Any, Dict, List, Literal, Optional\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"kibana_sample_data_logs\"\n",
    "IMAGE_PATH = \"imgs/dashboard.png\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "os.environ[\"ELASTICSEARCH_API_KEY\"] = getpass(\"Enter your Elasticsearch API key: \")\n",
    "os.environ[\"ELASTICSEARCH_URL\"] = getpass(\"Enter your Elasticsearch URL: \")\n",
    "os.environ[\"KIBANA_URL\"] = getpass(\"Enter your Kibana URL: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "langchain_llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    [os.getenv(\"ELASTICSEARCH_URL\")],\n",
    "    api_key=os.getenv(\"ELASTICSEARCH_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "class Visualization(BaseModel):\n",
    "    title: str = Field(description=\"The dashboard title\")\n",
    "    type: List[Literal[\"pie\", \"bar\", \"metric\"]]\n",
    "    field: Optional[str] = Field(\n",
    "        description=\"The field that this visualization use based on the provided mappings\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Dashboard(BaseModel):\n",
    "    title: str = Field(description=\"The dashboard title\")\n",
    "    visualizations: List[Visualization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the json templates\n",
    "\n",
    "There are 3 templates for each visualization type:\n",
    "- pie\n",
    "- bar\n",
    "- metric\n",
    "\n",
    "The templates are in the templates folder.\n",
    "\n",
    "The templates are in the following format:\n",
    "- insBar.json\n",
    "- insPie.json\n",
    "- insMetric.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {}\n",
    "template_dir = os.path.join(os.path.dirname(__file__), \"templates\")\n",
    "\n",
    "for vis_type in [\"pie\", \"bar\", \"metric\"]:\n",
    "    template_file = os.path.join(template_dir, f\"lns{vis_type.capitalize()}.json\")\n",
    "\n",
    "    try:\n",
    "        with open(template_file, \"r\") as f:\n",
    "            templates[vis_type] = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Template file {template_file} not found\")\n",
    "        templates[vis_type] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get templates by visualization type:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chart_template(vis_type: str):\n",
    "    return templates.get(vis_type, templates.get(\"bar\", {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to insert the values generated by the LLM into the template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_template_with_analysis(\n",
    "    template: Dict[str, Any],\n",
    "    visualization: Visualization,\n",
    "):\n",
    "    template_str = json.dumps(template)\n",
    "    replacements = {\n",
    "        \"{title}\": visualization.title,\n",
    "    }\n",
    "    if visualization.field:\n",
    "        replacements[\"{field}\"] = visualization.field\n",
    "    for placeholder, value in replacements.items():\n",
    "        template_str = template_str.replace(placeholder, str(value))\n",
    "\n",
    "    return json.loads(template_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve index mappings for the index that the dashboard is based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.indices.get_mapping(index=INDEX_NAME)\n",
    "index_mappings = result[list(result.keys())[0]][\"mappings\"][\"properties\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base64 = base64.b64encode(open(IMAGE_PATH, \"rb\").read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_schema = json.dumps(Dashboard.model_json_schema(), indent=2)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "    You are an expert in analyzing Kibana dashboards from images for the version 9.0.0 of Kibana.\n",
    "\n",
    "    You will be given a dashboard image and a Elasticsearch index mappings.\n",
    "\n",
    "    Below is the index mappings for the index that the dashboard is based on.\n",
    "    Use this to help you understand the data and the fields that are available.\n",
    "\n",
    "    Index Mappings:\n",
    "    {index_mappings}\n",
    "\n",
    "    Return a JSON object with the following structure (see JSON schema below):\n",
    "    {dashboard_schema}\n",
    "    \n",
    "    There are some things to consider:\n",
    "    - field: The field that is relevant for the visualization, this is the data that will be used to generate the chart and can be found in the index mappings.\n",
    "    - If you choose a field that has multi-field, you can use the field name with the suffix .keyword to get the multi-field. For example: \n",
    "        'field_name': {{\n",
    "            'type': 'text',\n",
    "            'fields': {{\n",
    "                'keyword': {{\n",
    "                    'type': 'keyword',\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "        Here you can use the field_name.keyword to get the multi-field.\n",
    "        \n",
    "        'field_name': {{\n",
    "            'type': 'keyword',\n",
    "        }}\n",
    "        Here you can use the field_name to get the single field.\n",
    "    \n",
    "    - Only include the fields that are relevant for each visualization, based on what is visible in the image. The output must be a JSON object matching the schema above.\n",
    "    \"\"\"\n",
    "\n",
    "try:\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"},\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    result = json.loads(content)\n",
    "    dashboard_values = Dashboard(**result)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to analyze image and match fields: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels = []\n",
    "for vis in dashboard_values.visualizations:\n",
    "    for vis_type in vis.type:\n",
    "        template = get_chart_template(vis_type)\n",
    "        filled_panel = fill_template_with_analysis(template, vis)\n",
    "        panels.append(filled_panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the dashboard\n",
    "\n",
    "Here is called the API /api/generate-dashboard. The templates with the values generated by the LLM are sent to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dashboard_id = str(uuid.uuid4())\n",
    "\n",
    "    # post request to create the dashboard endpoint\n",
    "    url = f\"{os.getenv('KIBANA_URL')}/api/dashboards/dashboard/{dashboard_id}\"\n",
    "\n",
    "    dashboard_config = {\n",
    "        \"attributes\": {\n",
    "            \"title\": \"Generated Dashboard by LLM\",\n",
    "            \"description\": \"Generated by AI\",\n",
    "            \"timeRestore\": False,\n",
    "            \"panels\": panels,  # Visualizations with the values generated by the LLM\n",
    "            \"timeFrom\": \"now-7d/d\",\n",
    "            \"timeTo\": \"now\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"kbn-xsrf\": \"true\",\n",
    "        \"Authorization\": f\"ApiKey {os.getenv('ELASTICSEARCH_API_KEY')}\",\n",
    "    }\n",
    "\n",
    "    requests.post(\n",
    "        url,\n",
    "        headers=headers,\n",
    "        json=dashboard_config,\n",
    "    )\n",
    "\n",
    "    # Url to the generated dashboard\n",
    "    dashboard_url = f\"{os.getenv('KIBANA_URL')}/app/dashboards#/view/{dashboard_id}\"\n",
    "\n",
    "    print(\"Dashboard URL: \", dashboard_url)\n",
    "    print(\"Dashboard ID: \", dashboard_id)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create dashboard: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
