{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From image idea to Kibana dashboard using AI\n",
    "\n",
    "This notebook is based on the article [From image idea to Kibana dashboard using AI](https://www.elastic.co/search-labs/blog/from-image-idea-to-kibana-dashboard-using-ai). With the following code, we can generate a Kibana dashboard from an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install elasticsearch pydantic langchain langchain-openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "import uuid\n",
    "from getpass import getpass\n",
    "from typing import Any, Dict, List, Literal, Optional\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from langchain.chat_models import init_chat_model\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "os.environ[\"ELASTICSEARCH_API_KEY\"] = getpass(\"Enter your Elasticsearch API key: \")\n",
    "os.environ[\"ELASTICSEARCH_URL\"] = getpass(\"Enter your Elasticsearch URL: \")\n",
    "os.environ[\"KIBANA_URL\"] = getpass(\"Enter your Kibana URL: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the dashboard schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualization(BaseModel):\n",
    "    title: str = Field(description=\"The dashboard title\")\n",
    "    type: List[Literal[\"pie\", \"bar\", \"metric\"]]\n",
    "    field: Optional[str] = Field(\n",
    "        description=\"The field that this visualization use based on the provided mappings\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Dashboard(BaseModel):\n",
    "    title: str = Field(description=\"The dashboard title\")\n",
    "    visualizations: List[Visualization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the json templates\n",
    "\n",
    "There are 3 templates for each visualization type:\n",
    "- pie\n",
    "- bar\n",
    "- metric\n",
    "\n",
    "The templates are in the templates folder.\n",
    "\n",
    "The templates are in the following format:\n",
    "- insBar.json\n",
    "- insPie.json\n",
    "- insMetric.json\n",
    "\n",
    "You can find the templates here: https://github.com/Delacrobix/mcp_dashboards/tree/notebook/templates download it and store it in the *templates* folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 templates\n",
      "Loaded 2 templates\n",
      "Loaded 3 templates\n"
     ]
    }
   ],
   "source": [
    "templates = {}\n",
    "base_dir = os.getcwd()\n",
    "template_dir = os.path.join(base_dir, \"templates\")\n",
    "\n",
    "for vis_type in [\"pie\", \"bar\", \"metric\"]:\n",
    "    template_file = os.path.join(template_dir, f\"lns{vis_type.capitalize()}.json\")\n",
    "\n",
    "    try:\n",
    "        with open(template_file, \"r\") as f:\n",
    "            templates[vis_type] = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Template file {template_file} not found\")\n",
    "        templates[vis_type] = {}\n",
    "\n",
    "    if not templates:\n",
    "        print(\"No templates found\")\n",
    "        break\n",
    "\n",
    "    print(f\"Loaded {len(templates)} templates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to insert the values generated by the LLM into the template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_template_with_analysis(\n",
    "    template: Dict[str, Any],\n",
    "    visualization: Visualization,\n",
    "):\n",
    "    template_str = json.dumps(template)\n",
    "    replacements = {\n",
    "        \"{title}\": visualization.title,\n",
    "    }\n",
    "    if visualization.field:\n",
    "        replacements[\"{field}\"] = visualization.field\n",
    "    for placeholder, value in replacements.items():\n",
    "        template_str = template_str.replace(placeholder, str(value))\n",
    "\n",
    "    return json.loads(template_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve index mappings for the index that the dashboard is based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"kibana_sample_data_logs\"\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    [os.getenv(\"ELASTICSEARCH_URL\")],\n",
    "    api_key=os.getenv(\"ELASTICSEARCH_API_KEY\"),\n",
    ")\n",
    "\n",
    "result = es_client.indices.get_mapping(index=INDEX_NAME)\n",
    "index_mappings = result[list(result.keys())[0]][\"mappings\"][\"properties\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading image \n",
    "You can download and use testing images here: https://github.com/Delacrobix/mcp_dashboards/tree/notebook/imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"dashboard.png\"\n",
    "\n",
    "image_base64 = base64.b64encode(open(IMAGE_PATH, \"rb\").read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard values:  title='Web Traffic Dashboard' visualizations=[Visualization(title='Visits', type=['metric'], field=None), Visualization(title='Most used OS', type=['pie'], field='machine.os.keyword'), Visualization(title='Unique Visitors', type=['metric'], field=None), Visualization(title='State Geo Dest', type=['bar'], field='geo.dest')]\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "    You are an expert in analyzing Kibana dashboards from images for the version 9.0.0 of Kibana.\n",
    "\n",
    "    You will be given a dashboard image and a Elasticsearch index mappings.\n",
    "\n",
    "    Below is the index mappings for the index that the dashboard is based on.\n",
    "    Use this to help you understand the data and the fields that are available.\n",
    "\n",
    "    Index Mappings:\n",
    "    {index_mappings}\n",
    "    \n",
    "    There are some things to consider:\n",
    "    - field: The field that is relevant for the visualization, this is the data that will be used to generate the chart and can be found in the index mappings.\n",
    "    - If you choose a field that has multi-field, you can use the field name with the suffix .keyword to get the multi-field. For example: \n",
    "        'field_name': {{\n",
    "            'type': 'text',\n",
    "            'fields': {{\n",
    "                'keyword': {{\n",
    "                    'type': 'keyword',\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "        Here you can use the field_name.keyword to get the multi-field.\n",
    "        \n",
    "        'field_name': {{\n",
    "            'type': 'keyword',\n",
    "        }}\n",
    "        Here you can use the field_name to get the single field.\n",
    "    - Only include the fields that are relevant for each visualization, based on what is visible in the image. \n",
    "    \"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"source_type\": \"base64\",\n",
    "                \"data\": image_base64,\n",
    "                \"mime_type\": \"image/png\",\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "try:\n",
    "    llm = init_chat_model(\"gpt-4.1-mini\")\n",
    "    llm = llm.with_structured_output(Dashboard)\n",
    "    response = llm.invoke(message)\n",
    "\n",
    "    dashboard_values = response\n",
    "\n",
    "    print(\"Dashboard values generated by the LLM successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to analyze image and match fields: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the template with the values generated by the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels = []\n",
    "for vis in dashboard_values.visualizations:\n",
    "    for vis_type in vis.type:\n",
    "        template = templates.get(vis_type, templates.get(\"bar\", {}))\n",
    "        filled_panel = fill_template_with_analysis(template, vis)\n",
    "        panels.append(filled_panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the dashboard\n",
    "\n",
    "Here is called the API /api/generate-dashboard. The templates with the values generated by the LLM are sent to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard URL:  https://articles-cluster-9-0.kb.us-central1.gcp.cloud.es.io/app/dashboards#/view/644da5a6-adb7-4494-a2ed-52f64459b469\n",
      "Dashboard ID:  644da5a6-adb7-4494-a2ed-52f64459b469\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dashboard_id = str(uuid.uuid4())\n",
    "\n",
    "    # post request to create the dashboard endpoint\n",
    "    url = f\"{os.getenv('KIBANA_URL')}/api/dashboards/dashboard/{dashboard_id}\"\n",
    "\n",
    "    dashboard_config = {\n",
    "        \"attributes\": {\n",
    "            \"title\": \"Generated Dashboard by LLM\",\n",
    "            \"description\": \"Generated by AI\",\n",
    "            \"timeRestore\": False,\n",
    "            \"panels\": panels,  # Visualizations with the values generated by the LLM\n",
    "            \"timeFrom\": \"now-7d/d\",\n",
    "            \"timeTo\": \"now\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"kbn-xsrf\": \"true\",\n",
    "        \"Authorization\": f\"ApiKey {os.getenv('ELASTICSEARCH_API_KEY')}\",\n",
    "    }\n",
    "\n",
    "    requests.post(\n",
    "        url,\n",
    "        headers=headers,\n",
    "        json=dashboard_config,\n",
    "    )\n",
    "\n",
    "    # Url to the generated dashboard\n",
    "    dashboard_url = f\"{os.getenv('KIBANA_URL')}/app/dashboards#/view/{dashboard_id}\"\n",
    "\n",
    "    print(\"Dashboard URL: \", dashboard_url)\n",
    "    print(\"Dashboard ID: \", dashboard_id)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create dashboard: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
